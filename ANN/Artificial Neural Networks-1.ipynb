{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makine Öğrenmesi \n",
    "\n",
    "\"Machine learning is an application of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. Machine learning focuses on the development of computer programs that can access data and use it learn for themselves.\"\n",
    "\n",
    "\"Yapay zeka uygulamalarından olan makine öğrenmesi herhangi direkt programlama yapılmadan bir sistemin geçmiş tecrübelerden öğrenmesi ve kendisini geliştirmesi olarak tanımlanabilir. Makine öğrenmesi bilgisayar programlarının verilerden kendi kendine öğrenebilmesine odaklanır.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/ML.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Makine öğrenimi nasıl çalışır?**\n",
    "Makine öğrenimi, tüm öğrenmenin gerçekleştiği beyindir. Makinenin öğrenme şekli insana benzer. İnsanlar deneyimlerinden öğrenirler. Ne kadar çok şey bilirsek, o kadar kolay tahmin edebiliriz. Benzer şekilde, bilinmeyen bir durumla karşılaştığımızda, başarı olasılığı bilinen durumdan daha düşüktür. Makineler aynı şekilde eğitilir. Doğru bir tahmin yapmak için makine bir örnek görür. Makineye benzer bir örnek verdiğimizde, sonucu anlayabilir. Ancak, bir insan gibi, beslemesi daha önce görülmemiş bir örnek ise, makine de tahmin etmekte zorluklar yaşar.\n",
    "\n",
    "Makine öğrenmenin temel amacı **öğrenme ve çıkarım** yapmaktır. Her şeyden önce, makine karakteristik niteliklerin keşfi yoluyla öğrenir. Bu keşif veriler sayesinde yapılır. Veri bilimcisinin önemli bir parçası, makineye hangi verilerin verileceğini dikkatlice seçmektir. Bir sorunu çözmek için kullanılan niteliklerin listesine unsur vektörü **(feature vector)** denir. Bir unsur vektörünü, bir sorunu çözmek için kullanılan bir veri alt kümesi olarak düşünebilirsiniz. \n",
    "Makine gerçekliği basitleştirmek ve bu keşfi bir modele dönüştürmek için bazı süslü algoritmalar kullanır. Bu nedenle, öğrenme aşaması verileri tanımlamak ve bir modele özetlemek için kullanılır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/MLprocess.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Çıkarım Yapmak**\n",
    "\n",
    "Model oluşturulduğunda, daha önce hiç görmeilen verilerde ne kadar güçlü olduğunu test etmek mümkündür. Yeni veriler bir özellik vektörüne dönüştürülür, modelin içinden geçilir ve bir tahmin verir. Bu makine öğreniminin en güzel kısmı. Kuralları güncellemeye veya modeli tekrar eğitmeye gerek yoktur. Yeni veriler üzerinde çıkarım yapmak için önceden eğitilmiş modeli kullanabilirsiniz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/inferring.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning programlarının ömrü basittir ve aşağıdaki noktalarda özetlenebilir:\n",
    "    \n",
    "1. Bir soru tanımla\n",
    "2. Veri toplayın\n",
    "3. Verileri görselleştirme\n",
    "4. Algoritmayı eğit\n",
    "5. Algoritmayı test Et\n",
    "6. Geri bildirim toplayın\n",
    "7. İyileştirmeler yap\n",
    "8. Sonuçlar tatmin edici olana kadar 4-7 maddelerini tekrar et.\n",
    "9. Tahmin yapmak için modeli kullanın"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Makine öğrenmesi algoritmaları ve nerede kullanıldıkları?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/methods.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Denetimli öğrenme (Supervised Learning)**\n",
    "\n",
    "Algoritma, verilen girdilerin belirli bir çıktıyla ilişkisini öğrenmek için insanlardan gelen eğitim verilerini ve geri bildirimleri kullanır. Örneğin, bir uygulayıcı, kutu içeceklerin satışını tahmin etmek için giriş verileri olarak pazarlama giderlerini ve hava tahminlerini kullanabilir.\n",
    "\n",
    "Çıktı verileri bilindiğinde denetimli öğrenmeyi kullanabilirsiniz. Algoritma yeni verileri öngörür.\n",
    "\n",
    "Denetimli öğrenmenin iki kategorisi vardır:\n",
    "\n",
    "1. Sınıflandırma problemi\n",
    "<img src=\"images/winequality.PNG\">\n",
    "\n",
    "2. Regresyon problemi\n",
    "<img src=\"images/concrete.PNG\">\n",
    "\n",
    "\n",
    "\n",
    "Doğru çıktı değerleri (bilininen sonuçlar/output) sürekli olan veri setlerinde regresyon yöntemi kullanılırken, doğru çıktı değerleri süreksiz olan veri setleri için sınıflandırma yöntemleri kullanılır. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Denetimsiz Öğrenme (Unsupervised Learning)**\n",
    "\n",
    "Denetimsiz öğrenmede, bir algoritma, açık bir çıktı değişkeni verilmeden giriş verilerini araştırır (örn., karateristikleri belirlemek için müşteri demografik verilerini araştırır)\n",
    "\n",
    "Verileri nasıl sınıflandıracağınızı bilmediğinizde ve algoritmanın karakteristikleri bulmasını ve verileri sizin için sınıflandırmasını istediğinizde kullanabilirsiniz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lineer Denklemler ve Matrisler\n",
    "\n",
    "$a_1x_1+a_2x_2+\\dots+a_nx_n=y$ şeklindeki denklemlere lineer veya doğrusal denklemler denir. Bu tarz denklemlerin genel formunu $ax+b=y$ şeklinde gösterebiliriz. \n",
    "\n",
    "$x_1,x_2,\\dots,x_n$ 'ler bilinmeyenler olmak üzere doğrusal denklerin oluşturduğu \n",
    "\\begin{equation}\n",
    "a_{11}x_1+a_{12}x_2+\\dots+a_{1n}x_n=y_1 \\\\\n",
    "a_{21}x_1+a_{22}x_2+\\dots+a_{2n}x_n=y_2 \\\\\n",
    "a_{31}x_1+a_{32}x_2+\\dots+a_{3n}x_n=y_3 \\\\\n",
    "\\vdots \\\\\n",
    "a_{m1}x_1+a_{m2}x_2+\\dots+a_{mn}x_n=y_m\n",
    "\\end{equation}\n",
    "\n",
    "şeklindeki denklemlerin tamamına doğrusal denklem sistemleri denir. Bu denklemlerde a ve y değişkenleri sabit değişkenlerdir. \n",
    "\n",
    "Doğrusal denklem sistemlerini matris formatında $Ax=Y$ şeklinde gösterilebilir. \n",
    "\n",
    "\\begin{equation*}\n",
    "A = \n",
    "\\begin{bmatrix}\n",
    "a_{11} & \\dots & a_{1n} \\\\\n",
    "\\vdots & \\vdots & \\dots \\\\\n",
    "a_{m1} & \\dots & a_{mn}\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "Y = \n",
    "\\begin{bmatrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "\\vdots \\\\\n",
    "y_m\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "X = \n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "\\vdots \\\\\n",
    "x_n\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "Bu denklemlerin çözümü $n \\times 1$ boyutlu bir vektördür.\n",
    "\n",
    "## Matrisler\n",
    "\n",
    "Pdf Dökümana Bakın"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doğrusal Regrasyon (Linear Regression)\n",
    "\n",
    "Lineer regresyon analizi, bir değişkenin değerini başka bir değişkenin değerine göre tahmin etmek için kullanılır. Tahmin etmek istediğiniz değişken, bağımlı değişken olarak adlandırılır. Diğer değişkenin değerini tahmin etmek için kullandığınız değişken ise bağımsız değişken olarak adlandırılır.\n",
    "\n",
    "<img src=\"images/linear2.PNG\">\n",
    "\n",
    "Basit doğrusal regresyon, bağımsız değişkenlerin sayısının bir olduğu ve bağımsız (x) ve bağımlı (y) değişken arasında doğrusal bir ilişki olduğu bir regresyon analizi türüdür. Yukarıdaki grafikteki kırmızı çizgi, en uygun düz çizgi olarak adlandırılır. Verilen veri noktalarına dayanarak, noktaları en iyi modelleyen bir çizgi çizmeye çalışıyoruz. Çizgi, aşağıda gösterilen doğrusal denklemlere göre modellenebilir.\n",
    "\n",
    "\\begin{equation}\n",
    "y=b+w_1x\n",
    "\\end{equation}\n",
    "\n",
    "<img src=\"images/linear.PNG\">\n",
    "\n",
    "Doğrusal regresyon algoritmasının nedeni $b$ ve $w_1$ için en iyi değerleri bulmaktır. Algoritmaya geçmeden önce, doğrusal regresyonu daha iyi anlamak için bilmeniz gereken iki önemli kavrama bir göz atalım.\n",
    "\n",
    "**Notasyonlar**\n",
    "\n",
    "$m$= Eğitim seti örnek sayısı\n",
    "\n",
    "$x$= Input Features\n",
    "\n",
    "$y$= Output Variable\n",
    "\n",
    "$(x,y)$= Tek bir veri örneği\n",
    "\n",
    "$(x^i,y^i)$= i inci veri örneği\n",
    "\n",
    "\n",
    "$h_W(x)=b+W_1x$ ifadesi bağımsız değişken ile bağımlı değişken arasındaki ilişkiyi ortaya koyan eğridir. Bizim Örneğimizde ev $m^2$ si ile ev fiyatı arasındaki ilişki. \n",
    "\n",
    "## Cost Function (Maliyet Fonksiyonu)\n",
    "\n",
    "Maliyet fonksiyonu tahmin değerleri ile gerçek değerler arasındaki farklardan meydana gelir ve bir doğrusal regresyon modelindeki amaç bu farkın minimize edilmesidir. Bu noktadan hareketle maliyet fonksiyonu \n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{1}{2m} \\sum_{i=1}^{m}{(b+W1x^i)-y^i}\n",
    "\\end{equation}\n",
    "\n",
    "Yukarıdaki ifadeyi kısaca $J(b,W_1)$ ifadesi ile gösterebiliriz ve bu ifade ortalama hatayı ifade etmektedir. Öte yandan $h_W(x)=b+W_1x$ ifadesi bizim hipotezimizi ifade eder. Hipotezi kısaca $b+W_1x$ doğrusunun söz konusu veri seti için en ideal doğru olduğunu iddia etmek diye tanımlayabiliriz. \n",
    "\n",
    "\n",
    "Şimdi $h_{W(x)}$ ile $J(b,W_1)$ ifadesi arasındaki ilişkiye bakalım. Örneğin aşağıdaki veri seti verilmiş olsun:\n",
    "\n",
    "X=\\{(1,1),(2,2),(3,3)\\} \n",
    "\n",
    "Not: $b$=0\n",
    "\n",
    "<img src=\"images/example.PNG\">\n",
    "\n",
    "Eğer $W_1=0.5$ dersek:\n",
    "\n",
    "\\begin{equation}\n",
    "J(W_1)=\\frac{1}{2m} \\sum_{i=1}^{m}{(W_0+W_1x^i)-y^i}\\\\\n",
    "J(W_1)=\\frac{1}{2m}\\sum_{i=1}^{m}{W_1x^{(i)}-y^{(i)}}\\\\\n",
    "J(W_1)=\\frac{1}{2m}((0.5-1)^2+(0.5-2)^2+(0.5-3)^2\n",
    "J(W_1)=\\frac{1}{6}\\times 3.5=0.58\n",
    "\\end{equation}\n",
    "\n",
    "Eğer $W_1=1$ dersek:\n",
    "\\begin{equation}\n",
    "J(W_1)=\\frac{1}{2m} \\sum_{i=1}^{m}{(b+W1x^i)-y^i}\\\\\n",
    "J(W_1)=\\frac{1}{2m}\\sum_{i=1}^{m}{W_1x^{(i)}-y^{(i)}}\\\\\n",
    "J(W_1)=\\frac{1}{2m}((0-1)^2+(0-2)^2+(0-3)^2\n",
    "J(W_1)=\\frac{1}{6}\\times 0=0\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Tekrar hatırlayalım! Amacımız Maliyet Fonksiyonunun minimize etmek\n",
    "\n",
    "<img src=\"images/Jexample.PNG\">\n",
    "\n",
    "\n",
    "## Gradient Descent\n",
    "\n",
    "Gradient Descent algoritması makine öğrenmesindeki bir çok fonksiyonu minimize etmek için kullanılır. Temel mantığu şudur:\n",
    "\n",
    "1. Rastgele $W_1$ ve $b$ değerleri seç \n",
    "2. Maliyet Fonksiyonu minumum olana kadar $W_1$ ve $b$ değerlerini değiştir. \n",
    "\n",
    "\\begin{equation}\n",
    "W_i:=W_i-\\alpha\\times \\partial \\frac{J(b,W_1)}{\\partial W_i}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "b:=b-\\alpha\\times \\partial \\frac{J(b,W_1)}{\\partial b}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Bu denklemde $\\alpha$=Öğrenme katsayıdır. \n",
    "\n",
    "<img src=\"images/updaterule.PNG\">\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\partial \\frac{J(b,W_1)}{\\partial b}=\\frac{1}{m}\\sum_{i=1}^{m}{h_w(x^{(i)})-y^{(i)}} \\\\\n",
    "\\partial \\frac{J(b,W_1)}{\\partial W_1}=\\frac{1}{m}\\sum_{i=1}^{m}({h_w(x^{(i)})-y^{(i)}}).x^{(i)}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "b:=b-\\alpha\\frac{1}{m}\\sum_{i=1}^{m}{h_w(x^{(i)})-y^{(i)}} \\\\\n",
    "W_1:=W_1-\\alpha\\frac{1}{m}\\sum_{i=1}^{m}{h_w(x^{(i)})-y^{(i)}}.x^{(i)}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Dikkat edilirse $W_1$ ve $b$ parameterelerinin optimum değeri $J$ fonksiyonun bunlara göre türevi alınarak bulunmaktadır. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Örnek:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10)\n",
      "(442,)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)\n",
    "\n",
    "#print(diabetes_X)\n",
    "#print(diabetes_y)\n",
    "\n",
    "print(diabetes_X.shape)\n",
    "print(diabetes_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean Squared Error**\n",
    "\n",
    "$\\text{MSE}(y, \\hat{y}) = \\frac{1}{n_\\text{samples}} \\sum_{i=0}^{n_\\text{samples} - 1} (y_i - \\hat{y}_i)^2.$\n",
    "\n",
    "**Coefficient of determination**\n",
    "$R^2=\\dfrac{1-u}{v}$\n",
    "\n",
    "$u=\\sum_{i=1}^{m}{y_{true}^i-y_{pred}^i}$\n",
    "\n",
    "$v=\\sum_{i=1}^{m}{y_{true}^i-\\overline{y}_{pred}}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442,)\n"
     ]
    }
   ],
   "source": [
    "# Use only one feature\n",
    "diabetes_X = diabetes_X[:, 2]\n",
    "print(diabetes_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 1)\n"
     ]
    }
   ],
   "source": [
    "# Tek bir sütun olduğunda kullanışlı\n",
    "#reshape the dataset\n",
    "diabetes_X=diabetes_X.reshape(-1,1)\n",
    "print(diabetes_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training/testing sets\n",
    "diabetes_X_train = diabetes_X[:-20]\n",
    "diabetes_X_test = diabetes_X[-20:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the targets into training/testing sets\n",
    "diabetes_y_train = diabetes_y[:-20]\n",
    "diabetes_y_test = diabetes_y[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model using the training sets\n",
    "regr.fit(diabetes_X_train, diabetes_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the testing set\n",
    "diabetes_y_pred = regr.predict(diabetes_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: \n",
      " 152.91886182616167\n",
      "Coefficients: \n",
      " [938.23786125]\n",
      "Mean squared error: 2548.07\n",
      "Coefficient of determination: 0.47\n"
     ]
    }
   ],
   "source": [
    "#Constat value\n",
    "print('Intercept: \\n', regr.intercept_)\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(diabetes_y_test, diabetes_y_pred))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(diabetes_y_test, diabetes_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(diabetes_X_test, diabetes_y_test,  color='black')\n",
    "plt.plot(diabetes_X_test, diabetes_y_pred, color='blue', linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization (Normalizasyon)\n",
    "Normalizasyon, makine öğrenimi için veri hazırlamanın bir parçası olarak sıklıkla uygulanan bir tekniktir. Normalleştirmenin amacı, veri kümesindeki sayısal sütunların değerlerini, değer aralıklarındaki farklılıkları bozmadan ortak bir ölçeğe dönüştürmektir.\n",
    "\n",
    "Örnek: \n",
    "\n",
    "Ev net metrekaresi=$x_1 \\rightarrow (0-500 m^2)$ \n",
    "\n",
    "Ev oda sayısı= $x_2 \\rightarrow (1-5)$ \n",
    "\n",
    "Bu tarz durumlarda normalizasyon yapmamız gerekmektedir. \n",
    "\n",
    "**Örnek:**\n",
    "\n",
    "Veri kümelerinin standardizasyonu, `scikit-learn` uygulamasında uygulanan birçok makine öğrenmesi algoritmaları için ortak bir gerekliliktir; bireysel özellikler (features) standart normalde dağıtılmış verilere benzemiyorsa kötü davranabilirler: sıfır ortalama ve birim varyansı olan Gaussian dağılımı bu tarz veriler için kullanılabilir. Normalizasyon algoritmanın daha hızlı öğrenmesine yardımcı olacaktır. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(422, 10)\n",
      "[[-0.00188202 -0.04464164 -0.05147406 -0.02632783 -0.00844872 -0.01916334\n",
      "   0.07441156 -0.03949338 -0.06832974 -0.09220405]\n",
      " [ 0.08529891  0.05068012  0.04445121 -0.00567061 -0.04559945 -0.03419447\n",
      "  -0.03235593 -0.00259226  0.00286377 -0.02593034]\n",
      " [-0.08906294 -0.04464164 -0.01159501 -0.03665645  0.01219057  0.02499059\n",
      "  -0.03603757  0.03430886  0.02269202 -0.00936191]\n",
      " [ 0.00538306 -0.04464164 -0.03638469  0.02187235  0.00393485  0.01559614\n",
      "   0.00814208 -0.00259226 -0.03199144 -0.04664087]\n",
      " [-0.09269548 -0.04464164 -0.04069594 -0.01944209 -0.06899065 -0.07928784\n",
      "   0.04127682 -0.0763945  -0.04118039 -0.09634616]\n",
      " [-0.04547248  0.05068012 -0.04716281 -0.01599922 -0.04009564 -0.02480001\n",
      "   0.00077881 -0.03949338 -0.06291295 -0.03835666]\n",
      " [ 0.06350368  0.05068012 -0.00189471  0.06662967  0.09061988  0.10891438\n",
      "   0.02286863  0.01770335 -0.03581673  0.00306441]\n",
      " [ 0.04170844  0.05068012  0.06169621 -0.04009932 -0.01395254  0.00620169\n",
      "  -0.02867429 -0.00259226 -0.01495648  0.01134862]\n",
      " [-0.07090025 -0.04464164  0.03906215 -0.03321358 -0.01257658 -0.03450761\n",
      "  -0.02499266 -0.00259226  0.06773633 -0.01350402]]\n",
      "[[-0.00188202 -0.04464164 -0.05147406 -0.02632783 -0.00844872 -0.01916334\n",
      "   0.07441156 -0.03949338 -0.06832974 -0.09220405]\n",
      " [ 0.08529891  0.05068012  0.04445121 -0.00567061 -0.04559945 -0.03419447\n",
      "  -0.03235593 -0.00259226  0.00286377 -0.02593034]\n",
      " [-0.08906294 -0.04464164 -0.01159501 -0.03665645  0.01219057  0.02499059\n",
      "  -0.03603757  0.03430886  0.02269202 -0.00936191]\n",
      " [ 0.00538306 -0.04464164 -0.03638469  0.02187235  0.00393485  0.01559614\n",
      "   0.00814208 -0.00259226 -0.03199144 -0.04664087]\n",
      " [-0.09269548 -0.04464164 -0.04069594 -0.01944209 -0.06899065 -0.07928784\n",
      "   0.04127682 -0.0763945  -0.04118039 -0.09634616]\n",
      " [-0.04547248  0.05068012 -0.04716281 -0.01599922 -0.04009564 -0.02480001\n",
      "   0.00077881 -0.03949338 -0.06291295 -0.03835666]\n",
      " [ 0.06350368  0.05068012 -0.00189471  0.06662967  0.09061988  0.10891438\n",
      "   0.02286863  0.01770335 -0.03581673  0.00306441]\n",
      " [ 0.04170844  0.05068012  0.06169621 -0.04009932 -0.01395254  0.00620169\n",
      "  -0.02867429 -0.00259226 -0.01495648  0.01134862]\n",
      " [-0.07090025 -0.04464164  0.03906215 -0.03321358 -0.01257658 -0.03450761\n",
      "  -0.02499266 -0.00259226  0.06773633 -0.01350402]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)\n",
    "diabetes_X_train = diabetes_X[:-20]\n",
    "diabetes_X_test = diabetes_X[-20:]\n",
    "print(diabetes_X_train.shape)\n",
    "print(diabetes_X_train[1:10,:])\n",
    "\n",
    "diabetes_X_train = preprocessing.scale(diabetes_X_train)\n",
    "\n",
    "print(diabetes_X[1:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Daha sonra ölçekleyici örneği, eğitim kümesinde olduğu gibi onu dönüştürmek için yeni veriler üzerinde kullanılabilir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.78841234  1.06870575  1.28651799 ... -0.05642896  0.41185893\n",
      "  -0.36242002]\n",
      " [-0.04754245 -0.93571126 -1.09158939 ... -0.83058441 -1.42870118\n",
      "  -1.93553   ]\n",
      " [ 1.77635892  1.06870575  0.92413972 ... -0.05642896  0.05632452\n",
      "  -0.53721002]\n",
      " ...\n",
      " [-0.42752191 -0.93571126 -1.15953532 ... -0.83058441 -1.54883084\n",
      "  -0.10023502]\n",
      " [ 0.48442878 -0.93571126 -0.77450841 ...  0.71772649 -0.69694742\n",
      "   1.29808496]\n",
      " [ 0.78841234  1.06870575  0.33527503 ...  1.49188194  1.03471374\n",
      "   0.33673997]]\n",
      "[[-0.07816532  0.05068012  0.07786339  0.05285819  0.07823631  0.0644473\n",
      "   0.02655027 -0.00259226  0.04067226 -0.00936191]\n",
      " [ 0.0090156   0.05068012 -0.03961813  0.0287581   0.03833367  0.0735286\n",
      "  -0.07285395  0.1081111   0.01556684 -0.04664087]\n",
      " [ 0.00175052  0.05068012  0.01103904 -0.01944209 -0.01670444 -0.00381907\n",
      "  -0.04708248  0.03430886  0.02405258  0.02377494]\n",
      " [-0.07816532 -0.04464164 -0.04069594 -0.08141377 -0.10063757 -0.11279473\n",
      "   0.02286863 -0.0763945  -0.02028875 -0.05078298]\n",
      " [ 0.03081083  0.05068012 -0.03422907  0.0436772   0.05759701  0.06883138\n",
      "  -0.03235593  0.05755657  0.03546194  0.08590655]\n",
      " [-0.03457486  0.05068012  0.00564998 -0.00567061 -0.07311851 -0.06269098\n",
      "  -0.00658447 -0.03949338 -0.04542096  0.03205916]\n",
      " [ 0.04897352  0.05068012  0.08864151  0.0872869   0.03558177  0.02154596\n",
      "  -0.02499266  0.03430886  0.06604821  0.13146972]\n",
      " [-0.04183994 -0.04464164 -0.03315126 -0.02288496  0.04658939  0.04158746\n",
      "   0.05600338 -0.02473293 -0.02595242 -0.03835666]\n",
      " [-0.00914709 -0.04464164 -0.05686312 -0.05042793  0.02182224  0.04534524\n",
      "  -0.02867429  0.03430886 -0.00991896 -0.01764613]\n",
      " [ 0.07076875  0.05068012 -0.03099563  0.02187235 -0.03734373 -0.04703355\n",
      "   0.03391355 -0.03949338 -0.01495648 -0.0010777 ]\n",
      " [ 0.0090156  -0.04464164  0.05522933 -0.00567061  0.05759701  0.04471895\n",
      "  -0.00290283  0.02323852  0.05568355  0.10661708]\n",
      " [-0.02730979 -0.04464164 -0.06009656 -0.02977071  0.04658939  0.01998022\n",
      "   0.12227286 -0.03949338 -0.05140054 -0.00936191]\n",
      " [ 0.01628068 -0.04464164  0.00133873  0.00810087  0.0053108   0.01089891\n",
      "   0.03023191 -0.03949338 -0.04542096  0.03205916]\n",
      " [-0.01277963 -0.04464164 -0.02345095 -0.04009932 -0.01670444  0.00463594\n",
      "  -0.01762938 -0.00259226 -0.03845911 -0.03835666]\n",
      " [-0.05637009 -0.04464164 -0.07410811 -0.05042793 -0.02496016 -0.04703355\n",
      "   0.09281975 -0.0763945  -0.0611766  -0.04664087]\n",
      " [ 0.04170844  0.05068012  0.01966154  0.05974393 -0.00569682 -0.00256647\n",
      "  -0.02867429 -0.00259226  0.03119299  0.00720652]\n",
      " [-0.00551455  0.05068012 -0.01590626 -0.06764228  0.0493413   0.07916528\n",
      "  -0.02867429  0.03430886 -0.01811827  0.04448548]\n",
      " [ 0.04170844  0.05068012 -0.01590626  0.01728186 -0.03734373 -0.01383982\n",
      "  -0.02499266 -0.01107952 -0.04687948  0.01549073]\n",
      " [-0.04547248 -0.04464164  0.03906215  0.00121513  0.01631843  0.01528299\n",
      "  -0.02867429  0.02655962  0.04452837 -0.02593034]\n",
      " [-0.04547248 -0.04464164 -0.0730303  -0.08141377  0.08374012  0.02780893\n",
      "   0.17381578 -0.03949338 -0.00421986  0.00306441]]\n"
     ]
    }
   ],
   "source": [
    "scaler=preprocessing.StandardScaler().fit(diabetes_X_train)\n",
    "scaler.transform(diabetes_X_train)\n",
    "scaler.transform(diabetes_X_test)\n",
    "\n",
    "print(diabetes_X_train)\n",
    "print(diabetes_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lojistik Regresyon\n",
    "\n",
    "Daha önceki derlerimizde bahsettiğimiz gibi. Denetimli öğrenme ile regresyon ve sınıflandırma problemlerini çözebiliriz. Lojistik regresyon sınıflandırma problemlerinin ve yapay sinir ağlarının en temel modelidir. Doğrusal regresyon problemlerinden farkı çıktınının reel değerlerden değilde kesikli değerlerden oluşmasıdır. Örneğin (Erkek/Bayan)\n",
    "\n",
    "Daha formal bir ifade ile lojistik Regresyon:\n",
    "\n",
    "$h_w(x)=\\hat{y}=P(y=1|x)$ şeklinde ifade edilebilir. Dolayısıyla $0\\geq h_w(x)\\geq1$ sistemin sağlanması gerekmektedir. \n",
    "\n",
    "Peki Lojistik regresyon girdi değerlerini nasıl 0 ve 1'lere dönüştürür?\n",
    "\n",
    "\n",
    "<img src=\"images/logreg.PNG\" style=\"width:500px;height:500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\sigma(z)$ fonskiyonu activation function (aktivasyon fonksiyonu) olarak adalandırılır. Sigmoid fonksiyonu aktivasyon fonksiyonlarından sadece bir tanesidir ve formulü aşağıdaki gibidir.\n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma(z)=\\dfrac{1}{1+e^{-z}}\\\\\n",
    "z=W^T+x\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Sigmoid fonksiyonunun grafiği aşağıdaki gibidir.\n",
    "\n",
    "<img src=\"images/sigmoid.PNG\" style=\"width:500px;height:500px;\" >\n",
    "\n",
    "Grafikten anlaşılacağı üzere eğer $\\sigma(z)$ ifadesindeki z değeri büyüdükçe tahmin 1'e küçüldükçe 0'a yaklaşmaktadır. Aşağıdaki örnekle kendinizi sınayın. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Örnek\n",
    "\n",
    "<img src=\"images/sigmoid2.PNG\">\n",
    "\n",
    "| x1 | x2 | hw(x)          |\n",
    "|----|:----:|:------------:|\n",
    "| 0  | 0  |  $$\\sigma(-30)$$|\n",
    "| 0  | 1  | $\\sigma(-10)$  |\n",
    "| 1  | 0  | $\\sigma(-10)$  |\n",
    "| 1  | 1  | $\\sigma(10)$   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lojistik regresyon yöntemindeki temel amaç $X$ değerleri verildiğinde $y$'nin 1 olma olasılığının hesaplanmasıdır. Bu problemde \n",
    "\n",
    "$X \\in R^{n_x}$\n",
    "\n",
    "Parametreler:\n",
    "\n",
    "$W \\in R^{n_x}$ , $b \\in R$\n",
    "\n",
    "Çıktı:\n",
    "\n",
    "$\\hat{y}=\\sigma(W^Tx+b)$\n",
    "\n",
    "Tekrar: $W^Tx+b$ değeri büyükse tahmin 1, küçükse 0'a yaklaşır. Aktivasyon fonksiyon grafiğini inceleyiniz. Burdaki $\\hat{y}$ değeri olasılığı ifade etmektedir. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Lojistik Regresyon(LR) Maliyet Fonksiyonu\n",
    "  \n",
    "  LR maliyet fonksiyonu doğrusal regresyon (DR) maliyet fonksiyonundan farklıdır. Bu farklılık kullanılan veri setlerindeki doğru çıktılardan ($y$) kaynaklanmaktadır. DR'da $y \\in R$ iken LR^'da $y \\in \\{0,1\\}$ dir. \n",
    "  \n",
    "**Kayıp Fonksiyonu** : Tek bir örnek bazında ne kadar hata yapıldığını gösteren fonksiyondur ve $L$ ile gösterili. Örneğin;\n",
    "\n",
    "$\\{(x^{(1)},y^{(1)}),\\dots, (x^{(1)},y^{(1)})\\} olarak verildiğinde LR için L fonksiyonunun formülü:\n",
    "\n",
    "\\begin{equation}\n",
    "L(y,\\hat{y})=-(ylog(\\hat{y})+(1-y)log(\\hat{1-y}))\n",
    "\\end{equation}\n",
    "\n",
    "şeklinde yazılabilir. \n",
    "\n",
    "**Maliyet Fonksiyonu**: Maliyet fonksiyonu bütün veri örneklerinde yapılan toplam hatayı ifade eder ve $J$ ile gösterilir. Bir başka deyişle:\n",
    "\n",
    "\\begin{equation}\n",
    "J(w,b)=\\dfrac{1}{m}\\sum_{i=1}^{m}L(y,\\hat{y})\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lojistik Regresyon(LR) Gradient Descent\n",
    "\n",
    "Tekrar hatırlatmak için Gradient Descent algoritması minumum maliyet fonksiyon değerini bulmak için kullanılır. Maliyet $J$, $w$ ve $b$ parametrelerinin fonksiyonu olduğu için bu parametrelerin maliyet fonskiyonunu minimize edecek optimum değerleri bulunur. Aşağıdaki örnekte bunu görebilirsiniz. Not: Grafikte $w$ parametresi $m$ ile gösterilmiştir ve örnel LR içindir. \n",
    "\n",
    "![Alt Text](https://alykhantejani.github.io/images/gradient_descent_line_graph.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lojistik Regresyon mimarisine baktığımızda 3 tane temel bileşen  mevcuttur. Bunlar ;\n",
    "\n",
    "$z=W^Tx+b$\n",
    "\n",
    "$\\hat{y}=a=\\sigma(z)$\n",
    "\n",
    "$L(y,\\hat{y})=-(ylog(\\hat{y})+(1-y)log(\\hat{1-y}))$\n",
    "\n",
    "Bu üç bileşen aşağıdaki şekilde kullanılır. \n",
    "\n",
    "<img src=\"images/LR.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tekrar hatırlatmak gerekirse Maliyet fonskiyonun minimize edilebimesi için $J(W,b)$ fonskiyonunun $W$ ve $b$ parametrelerine göre türevinin alınması gerekmektedir. Maliyet fonkiyonu ise aslında kayıp fonksiyonun her bir örnek için toplamından başka bir şey değildir. Dolayısıyla her bir veri örneği için kayıp fonksiyonunun $w$ ve $b$ parametrelerine göre türevlerini alıp bunların toplarsak istediğimiz sonucu elde etmiş oluruz. Burdaki türevleri zincir kuralını kullanarak şu şekilde hesaplarız. Zincir kuralının detaylarını herhangi bir kalkülüs kitabından öğrenebilirsiniz. \n",
    "\n",
    "Kayıp fonksiyonu $L$'nin $w1$ parametresine göre türevi: $dw_1=x_1*(a-y)$\n",
    "\n",
    "Kayıp fonksiyonu $L$'nin $w_2$ parametresine göre türevi: $dw_2=x_2*(a-y)$\n",
    "\n",
    "Kayıp fonksiyonu $L$'nin $w_{n_x}$ parametresine göre türevi: $dw_{n_x}=x_{n_x}*(a-y)$\n",
    "\n",
    "Kayıp fonksiyonu $L$'nin $b$ parametresine göre türevi: $db=(a-y)$\n",
    "\n",
    "Maliyet fonksiyonu $J(w,b)=\\dfrac{1}{m}\\sum_{i=1}^{m}L(y,\\hat{y})$ olduğuna göre maliyet fonksiyonu $J$'nin parametrelere göre türevini:\n",
    "\\begin{equation}\n",
    "\\partial \\frac{J(w,b)}{w1}=\\dfrac{1}{m}\\sum_{i=1}^{m}\\partial \\frac{L(y,\\hat{y})}{w_1}\n",
    "\\end{equation}\n",
    "\n",
    "Şekline yazabiliriz. \n",
    "\n",
    "$\\partial \\frac{L(y,\\hat{y})}{w_1}$ ifadesi d_{w_1}^{(i)} olduğundan, ifade \n",
    "\n",
    "\\begin{equation}\n",
    "\\partial \\frac{J(w,b)}{w_1}=\\dfrac{1}{m}\\sum_{i=1}^{m}dw_{1}^{(i)}\n",
    "\\end{equation}\n",
    "\n",
    "şeklinde sadeleştirilebilir. \n",
    "\n",
    "Bu ifade sadece $w_1$ parametresi içindir. Dolayısıyla bir $W=\\{w_1,w_2,\\dots,w_{n_x}\\}$ için genellenebilir. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "178px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
